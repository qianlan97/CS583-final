{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import socket\n",
    "import pickle\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        DROPOUT = 0.1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes),\n",
    "                nn.Dropout(DROPOUT)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.dropout(self.bn1(self.conv1(x))))\n",
    "        out = self.dropout(self.bn2(self.conv2(out)))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.2, 0.2, 0.2))\n",
    "])\n",
    "\n",
    "train_set=torchvision.datasets.CIFAR10(root=\"./dataset\",train=True,download=True,transform=trans)\n",
    "test_set=torchvision.datasets.CIFAR10(root=\"./dataset\",train=False,download=True,transform=trans)\n",
    "train_dataset=data.DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_dataset=data.DataLoader(test_set,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18().to(device)\n",
    "# summary(model, input_size=(3,32,32))\n",
    "\n",
    "optimizer1=torch.optim.SGD(model.parameters(),lr=0.01)          ## SGD more likely to get optimal. Adam converge faster\n",
    "loss=nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1):\n",
    "    losssum=0.0\n",
    "    total=0\n",
    "    accuracy=0.0\n",
    "    for i,(images,labels) in tqdm(enumerate(train_dataset)):\n",
    "        imgs=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        optimizer1.zero_grad()                                            ## clear gradient\n",
    "        output=model.forward(imgs)                                 ## predict\n",
    "        lossnum=loss(output,labels)                                   ## nn.CrossEntropyLoss()\n",
    "        lossnum.backward()                                                ## backpropagation\n",
    "        optimizer1.step()                                                     ## update parameters using gradients(using SGD defined above)\n",
    "        losssum=losssum+lossnum\n",
    "        accuracy+=(output.argmax(1)==labels).sum()      ## count number of correct predictions by argmax()\n",
    "        break\n",
    "    print(\"Epoch: {}'s accuracy is {}\".format(epoch, accuracy/len(train_set)))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     accuracy=0.0\n",
    "#     for data in test_dataset:\n",
    "#         imgs,labels=data\n",
    "#         imgs=imgs.to(device)\n",
    "#         labels=labels.to(device)\n",
    "\n",
    "#         output=model.forward(imgs)\n",
    "#         lossnum=loss(output,labels)\n",
    "#         accuracy+=(output.argmax(1)==labels).sum()\n",
    "#     print(\"Accuracy on the test dataset is {}\".format(accuracy/ len(test_set)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
